{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-16T14:13:27.731407Z",
          "start_time": "2026-02-16T14:13:27.710294Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydd39X5S1RYf",
        "outputId": "efcccf06-7ac6-4f1d-9b70-9a5227345f3a"
      },
      "source": [
        "import sys\n",
        "\n",
        "print(sys.executable)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0hn_9G--nIC"
      },
      "outputs": [],
      "source": [
        "# !nproc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMfQ7vpl1RYh",
        "outputId": "d3b06dc1-078a-41ea-8f56-8813d52e6ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (26.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-16T14:13:35.281385Z",
          "start_time": "2026-02-16T14:13:29.520627Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gk-Udze1RYh",
        "outputId": "3fc0c614-56cd-463a-a545-54160f5f63ef"
      },
      "source": [
        "%pip install opencv-python tqdm matplotlib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_FlbE9cH_U8y",
        "outputId": "f328b9b7-16cd-4cb3-be76-846f9f22fe18",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:13:40.667319Z",
          "start_time": "2026-02-16T14:13:36.521237Z"
        }
      },
      "source": [
        "# Install dependencies\n",
        "%pip install torch numpy torchvision"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu128)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu128)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Yt9xVz_cgf",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:13:51.434046Z",
          "start_time": "2026-02-16T14:13:40.758665Z"
        }
      },
      "source": [
        "# Import libraries\n",
        "# import mido\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "from os import mkdir\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from music21 import converter\n",
        "# from pdf2image import convert_from_path\n",
        "# from google.colab import files\n",
        "import shutil\n",
        "import numpy as np\n",
        "# import cv2\n",
        "import datetime"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ntqLWG0OzehP"
      },
      "outputs": [],
      "source": [
        "!rm -r ai_playing_music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z3CCkSfBWFz",
        "outputId": "231f5213-dba3-4459-faca-f32df0349cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai_playing_music'...\n",
            "remote: Enumerating objects: 95511, done.\u001b[K\n",
            "remote: Counting objects: 100% (6080/6080), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2787/2787), done.\u001b[K\n",
            "remote: Total 95511 (delta 2215), reused 6008 (delta 2154), pack-reused 89431 (from 1)\u001b[K\n",
            "Receiving objects: 100% (95511/95511), 1.61 GiB | 17.96 MiB/s, done.\n",
            "Resolving deltas: 100% (22125/22125), done.\n",
            "Updating files: 100% (46976/46976), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MichalMiszcz/ai_playing_music.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "6vkJgFT6sBPL"
      },
      "outputs": [],
      "source": [
        "# %cd /content/ai_playing_music\n",
        "# !git pull"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfJ01Z0l-6zN",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:13:59.392708Z",
          "start_time": "2026-02-16T14:13:59.386705Z"
        }
      },
      "source": [
        "global count_tracks\n",
        "count_tracks = 0"
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ6gl8DXYgER",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:00.464825Z",
          "start_time": "2026-02-16T14:14:00.459446Z"
        }
      },
      "source": [
        "HEIGHT = 416\n",
        "WIDTH = 608\n",
        "\n",
        "WHITE_KEYS_MIDI = [60, 62, 64, 65, 67, 69, 71, 72]\n",
        "NUM_NOTES = len(WHITE_KEYS_MIDI)\n",
        "\n",
        "VELOCITY = [0, 90]\n",
        "NUM_VELOCITIES = len(VELOCITY)\n",
        "\n",
        "DELTA_TIME = [0, 5040, 10080, 20160, 30240, 40320]\n",
        "NUM_DELTA_TIME = len(DELTA_TIME)"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhhg2yrhDKlP"
      },
      "source": [
        "# AutoEncoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73MQmCXnryF6"
      },
      "source": [
        "## Enkoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFg1K8AXrz8y",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:08.904491Z",
          "start_time": "2026-02-16T14:14:08.875329Z"
        }
      },
      "source": [
        "from typing import Callable, List, Optional, Type\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "\"\"\"From https://pytorch.org/vision/main/_modules/torchvision/models/resnet.html#resnet18\"\"\"\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlockEnc(nn.Module):\n",
        "    \"\"\"The basic block architecture of resnet-18 network.\n",
        "    \"\"\"\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"The encoder model.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[BasicBlockEnc],\n",
        "        layers: List[int],\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\n",
        "                \"replace_stride_with_dilation should be None \"\n",
        "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
        "            )\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlockEnc) and m.bn2.weight is not None:\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(\n",
        "        self,\n",
        "        block: Type[BasicBlockEnc],\n",
        "        planes: int,\n",
        "        blocks: int,\n",
        "        stride: int = 1,\n",
        "        dilate: bool = False,\n",
        "    ) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
        "            )\n",
        "        )\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)"
      ],
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLrQ7plQsCyW"
      },
      "source": [
        "## Dekoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W-7UDJdsEIm",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:24.285896Z",
          "start_time": "2026-02-16T14:14:24.266379Z"
        }
      },
      "source": [
        "from typing import Callable, List, Optional, Type\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "\"\"\"Based on https://pytorch.org/vision/main/_modules/torchvision/models/resnet.html#resnet18\"\"\"\n",
        "\n",
        "\n",
        "def conv3x3Transposed(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1, output_padding: int = 0) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\n",
        "    \"\"\"\n",
        "    return nn.ConvTranspose2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        output_padding = output_padding, # output_padding is neccessary to invert conv2d with stride > 1\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "def conv1x1Transposed(in_planes: int, out_planes: int, stride: int = 1, output_padding: int = 0) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\n",
        "    \"\"\"\n",
        "    return nn.ConvTranspose2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False, output_padding = output_padding)\n",
        "\n",
        "\n",
        "class BasicBlockDec(nn.Module):\n",
        "    \"\"\"The basic block architecture of resnet-18 network.\n",
        "    \"\"\"\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        output_padding: int = 0,\n",
        "        upsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3Transposed(planes, inplanes, stride, output_padding=output_padding)\n",
        "        self.bn1 = norm_layer(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3Transposed(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.upsample = upsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "        out = self.conv2(x)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv1(out)\n",
        "        out = self.bn1(out)\n",
        "\n",
        "        if self.upsample is not None:\n",
        "            identity = self.upsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"The decoder model.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[BasicBlockDec],\n",
        "        layers: List[int],\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64 # change from 2048 to 64. It should be the shape of the output image chanel.\n",
        "        self.dilation = 1\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.de_conv1 = nn.ConvTranspose2d(self.inplanes, 1, kernel_size=7, stride=2, padding=3, bias=False, output_padding=1)\n",
        "        self.bn1 = norm_layer(1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.unpool = nn.Upsample(scale_factor=2, mode='bilinear') # NOTE: invert max pooling\n",
        "\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1 ,output_padding = 0, last_block_dim=64)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlockDec) and m.bn2.weight is not None:\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(\n",
        "        self,\n",
        "        block: Type[BasicBlockDec],\n",
        "        planes: int,\n",
        "        blocks: int,\n",
        "        stride: int = 2,\n",
        "        output_padding: int = 1, # NOTE: output_padding will correct the dimensions of inverting conv2d with stride > 1.\n",
        "        # More info:https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html\n",
        "        last_block_dim: int = 0,\n",
        "    ) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        upsample = None\n",
        "        previous_dilation = self.dilation\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        self.inplanes = planes * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if last_block_dim == 0:\n",
        "            last_block_dim = self.inplanes//2\n",
        "\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            upsample = nn.Sequential(\n",
        "                conv1x1Transposed(planes * block.expansion, last_block_dim, stride, output_padding),\n",
        "                norm_layer(last_block_dim),\n",
        "            )\n",
        "\n",
        "        layers.append( block(\n",
        "                last_block_dim, planes, stride, output_padding, upsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
        "            ))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer1(x)\n",
        "\n",
        "        x = self.unpool(x)\n",
        "        x = self.de_conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)"
      ],
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc2Tw0Fzs42e"
      },
      "source": [
        "## Autoenkoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOUbsMkfs4iE",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:30.498090Z",
          "start_time": "2026-02-16T14:14:30.489567Z"
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AE(nn.Module):\n",
        "    \"\"\"Construction of resnet autoencoder.\n",
        "\n",
        "    Attributes:\n",
        "        network (str): the architectural type of the network. There are 2 choices:\n",
        "            - 'default' (default), related with the original resnet-18 architecture\n",
        "            - 'light', a samller network implementation of resnet-18 for smaller input images.\n",
        "        num_layers (int): the number of layers to be created. Implemented for 18 layers (default) for both types\n",
        "            of network, 34 layers for default only network and 20 layers for light network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, network='default', num_layers=18):\n",
        "        \"\"\"Initialize the autoencoder.\n",
        "\n",
        "        Args:\n",
        "            network (str): a flag to efine the network version. Choices ['default' (default), 'light'].\n",
        "             num_layers (int): the number of layers to be created. Choices [18 (default), 34 (only for\n",
        "                'default' network), 20 (only for 'light' network).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.network = network\n",
        "        if self.network == 'default':\n",
        "            if num_layers==18:\n",
        "                # resnet 18 encoder\n",
        "                self.encoder = Encoder(BasicBlockEnc, [2, 2, 2, 2])\n",
        "                # resnet 18 decoder\n",
        "                self.decoder = Decoder(BasicBlockDec, [2, 2, 2, 2])\n",
        "            elif num_layers==34:\n",
        "                # resnet 34 encoder\n",
        "                self.encoder = Encoder(BasicBlockEnc, [3, 4, 6, 3])\n",
        "                # resnet 34 decoder\n",
        "                self.decoder = Decoder(BasicBlockDec, [3, 4, 6, 3])\n",
        "            else:\n",
        "                raise NotImplementedError(\"Only resnet 18 & 34 autoencoder have been implemented for images size >= 64x64.\")\n",
        "        else:\n",
        "                raise NotImplementedError(\"Only default and light resnet have been implemented. Th light version corresponds to input datasets with size less than 64x64.\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"The forward functon of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.tensor): the batched input data\n",
        "\n",
        "        Returns:\n",
        "            x (torch.tensor): encoder result\n",
        "            z (torch.tensor): decoder result\n",
        "        \"\"\"\n",
        "        z = self.encoder(x)\n",
        "        x = self.decoder(z)\n",
        "        return x, z\n"
      ],
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFTmvT8CDP8B"
      },
      "source": [
        "# Music Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIaSgunDQPR",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:37.237824Z",
          "start_time": "2026-02-16T14:14:33.579430Z"
        }
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "# import mido\n",
        "\n",
        "note_to_index = {midi_num: i for i, midi_num in enumerate(WHITE_KEYS_MIDI)}\n",
        "velocity_to_index = {midi_num: i for i, midi_num in enumerate(VELOCITY)}\n",
        "delta_time_to_index = {midi_num: i for i, midi_num in enumerate(DELTA_TIME)}\n",
        "\n",
        "class MusicImageDataset(Dataset):\n",
        "    def __init__(self, image_root, midi_root, image_transform=None, max_seq_len=100, max_midi_files=100, modify_image=False):\n",
        "        self.image_root = image_root\n",
        "        self.midi_root = midi_root\n",
        "        self.image_transform = image_transform if image_transform else transforms.ToTensor()\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.modify_image = modify_image\n",
        "        self.targets = np.arange(0, max_midi_files)\n",
        "\n",
        "        midi_files = []\n",
        "        for root, dirs, files in os.walk(midi_root):\n",
        "            folder = os.path.basename(os.path.dirname(root))\n",
        "            author = os.path.basename(root)\n",
        "            for file in files:\n",
        "                if file.endswith('.mid'):\n",
        "                    midi_files.append((folder, author, os.path.join(root, file)))\n",
        "\n",
        "        random.shuffle(midi_files)\n",
        "        sorted_midi_files = sorted(midi_files[:max_midi_files], key=lambda x: x[2])\n",
        "        self.selected_midi_files = sorted_midi_files\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.midi_features = {}\n",
        "        records_to_remove = []\n",
        "\n",
        "        for folder, author, midi_file in self.selected_midi_files:\n",
        "            folder = os.path.splitext(os.path.basename(midi_file))[0]\n",
        "            file = os.path.splitext(os.path.basename(midi_file))[0] + \"-1\" # Added only for my files\n",
        "            image_dir = os.path.join(image_root, author, folder)\n",
        "\n",
        "            if os.path.exists(image_dir):\n",
        "                image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]\n",
        "                for file in image_files:\n",
        "                    self.image_paths.append(os.path.join(image_dir, file))\n",
        "\n",
        "        self.image_paths.sort()\n",
        "        print(f\"Selected {len(self.image_paths)} images.\")\n",
        "\n",
        "        if len(self.image_paths) == 0:\n",
        "            raise ValueError(\"No images found for the selected MIDI files. Check directory paths and file structure.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "\n",
        "        rel_path = os.path.relpath(img_path, self.image_root)\n",
        "        composer, piece, _ = rel_path.split(os.sep)\n",
        "        midi_key = f\"{composer}/{piece}\"\n",
        "\n",
        "        image = Image.open(img_path).convert('L')\n",
        "\n",
        "        apply_augmentation = random.randrange(0, 1)\n",
        "        # if apply_augmentation <= self.aug_prob:\n",
        "        #     if self.modify_image:\n",
        "        #         img_array = np.array(image)\n",
        "        #         # angle = random.uniform(-2, 2)\n",
        "        #         angle = 0\n",
        "        #         x_shift = random.randint(-10, 10)\n",
        "        #         y_shift = random.randint(0, 30)\n",
        "\n",
        "        #         rotated_array = modify_image_opencv(img_array, angle, x_shift, y_shift)\n",
        "\n",
        "        #         image = Image.fromarray(rotated_array)\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "    def modify_image_opencv(image_array, angle, x_shift, y_shift):\n",
        "        (h, w) = image_array.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "\n",
        "        matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "        matrix[0, 2] += x_shift\n",
        "        matrix[1, 2] += y_shift\n",
        "\n",
        "        rotated = cv2.warpAffine(image_array, matrix, (w, h), borderValue=(255, 255, 255))\n",
        "        return rotated"
      ],
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkv9_9e3FfbS"
      },
      "source": [
        "#Uczenie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0TzeGNxwmS0",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:41.426172Z",
          "start_time": "2026-02-16T14:14:40.146562Z"
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "def train_epoch(cae, device, dataloader, loss_fn, optimizer):\n",
        "    \"\"\"The training loop of autoencoder.\n",
        "\n",
        "    Args:\n",
        "        cae (classes.resnet_autoencoder.AE): the autoencoder model with - by default- random initilized weights.\n",
        "        device (str): if exists, the accelarator device used from the machine and supported from the pytorch else cpu.\n",
        "        dataloader (DataLoader): loader with the training data.\n",
        "        loss_fn (torch.nn.modules.loss): the loss function of the autoencoder\n",
        "        optimizer (torch.optim): the optimizer of the autoencoder\n",
        "\n",
        "    Returns:\n",
        "        (float): the mean of training loss\n",
        "    \"\"\"\n",
        "    # Set train mode for both the encoder and the decoder\n",
        "    cae.train()\n",
        "    train_loss = []\n",
        "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
        "    for _, x_batch in enumerate(dataloader):\n",
        "        # Move tensor to the proper device\n",
        "        x_batch = x_batch.to(device)\n",
        "        # CAE data\n",
        "        decoded_batch,_ = cae(x_batch)\n",
        "        # Evaluate loss\n",
        "        loss = loss_fn(decoded_batch, x_batch)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Print batch loss\n",
        "        train_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    return np.mean(train_loss)\n",
        "\n",
        "\n",
        "def test_epoch(cae, device, dataloader, loss_fn):\n",
        "    \"\"\"The validation loop of autoencoder on the test dataset.\n",
        "\n",
        "    Args:\n",
        "        cae (classes.resnet_autoencoder.AE): the autoencoder model.\n",
        "        device (str): if exists, the accelarator device used from the machine and supported from the pytorch else cpu.\n",
        "        dataloader (DataLoader): loader with the test data.\n",
        "        loss_fn (torch.nn.modules.loss): the loss function of the autoencoder.\n",
        "\n",
        "    Returns:\n",
        "        (float): the validation loss.\n",
        "    \"\"\"\n",
        "    # Set evaluation mode for encoder and decoder\n",
        "    cae.eval()\n",
        "    with torch.no_grad(): # No need to track the gradients\n",
        "        # Define the lists to store the outputs for each batch\n",
        "        decoded_data = []\n",
        "        original_data = []\n",
        "        for _, x_batch in enumerate(dataloader):\n",
        "            # Move tensor to the proper device\n",
        "            x_batch = x_batch.to(device)\n",
        "            # CAE data\n",
        "            decoded_batch,_ = cae(x_batch)\n",
        "            # Append the network output and the original image to the lists\n",
        "            decoded_data.append(decoded_batch.cpu())\n",
        "            original_data.append(x_batch.cpu())\n",
        "        # Create a single tensor with all the values in the lists\n",
        "        decoded_data = torch.cat(decoded_data)\n",
        "        original_data = torch.cat(original_data)\n",
        "        # Evaluate global loss\n",
        "        val_loss = loss_fn(decoded_data, original_data)\n",
        "\n",
        "    return val_loss.data\n",
        "\n",
        "\n",
        "def plot_ae_outputs(cae, dataset_opt, epoch, dataset, device, n=10):\n",
        "    \"\"\"Saving plot diagrams with reconstructed images in comparision with the original ones for a visual assessment.\n",
        "\n",
        "    Args:\n",
        "        cae (classes.resnet_autoencoder.AE): the trained autoencoder model.\n",
        "        dataset_opt (str): the name on the input dataset. Proposed choices ['train_dataset', 'test_dataset']\n",
        "        epoch (int): the present epoch in progress.\n",
        "        device (str): if exists, the accelarator device used from the machine and supported from the pytorch else cpu.\n",
        "        n (int): the number of original images to be plotted with their reconstructions. 10 (default).\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(64,32))\n",
        "    targets = np.array(dataset.targets)\n",
        "\n",
        "    print(\"targets: \", targets)\n",
        "\n",
        "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
        "\n",
        "    print(\"t_idx: \", t_idx)\n",
        "\n",
        "    for i in range(n):\n",
        "\n",
        "        ax = plt.subplot(2,n,i+1)\n",
        "        img = dataset[t_idx[i]][0] # dataset[t_idx[i]]-> tuple (X,Y)\n",
        "\n",
        "        print(img.dim())\n",
        "\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n//2:\n",
        "            ax.set_title('Original images from ' + dataset_opt + ' epoch=' + str(epoch))\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        img = img.unsqueeze(0).to(device) # img -> (3, xx, xx) but img.unsqueeze(0) -> (1,3,xx,xx)\n",
        "        cae.eval()\n",
        "        with torch.no_grad():\n",
        "            rec_img, _  = cae(img)\n",
        "\n",
        "        print(rec_img.dim())\n",
        "\n",
        "        rec_img = rec_img.cpu().squeeze() # rec_img -> (1, 3, xx, xx) but img.squeeze() -> (3,xx,xx)\n",
        "\n",
        "        print(rec_img.dim())\n",
        "\n",
        "        plt.imshow(rec_img, cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n//2:\n",
        "            ax.set_title('Reconstructed images from ' + dataset_opt + ' epoch=' + str(epoch))\n",
        "\n",
        "    if not os.path.isdir('output'):\n",
        "        os.mkdir('output')\n",
        "    # plt.show()\n",
        "    plt.savefig(f'output/{epoch}_epoch_from_{dataset_opt}.png')\n",
        "\n",
        "\n",
        "def checkpoint(model, epoch, val_loss, filename):\n",
        "    \"\"\"Saving the model at a specific state.\n",
        "\n",
        "    Args:\n",
        "        model (classes.resnet_autoencoder.AE): the trained autoencoder model.\n",
        "        epoch (int): the present epoch in progress.\n",
        "        val_loss (float): the validation loss.\n",
        "        filename (str): the relative path of the file where the model will be stored.\n",
        "    \"\"\"\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            # 'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            }, filename)\n",
        "\n",
        "def resume(model, filename):\n",
        "    \"\"\"Load the trained autoencoder model.\n",
        "\n",
        "    Args:\n",
        "        model (classes.resnet_autoencoder.AE): the untrained autoencoder model.\n",
        "        filename (str): the relative path of the file where the model is stored.\n",
        "\n",
        "    Results:\n",
        "        model (classes.resnet_autoencoder.AE): the loaded autoencoder model.\n",
        "        epoch (int): the last epoch of the training procedure of the model.\n",
        "        loss (float): the validation loss of the last epoch.\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(filename)\n",
        "    model = model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['val_loss']\n",
        "    return model, epoch, loss"
      ],
      "outputs": [],
      "execution_count": 52
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fanelpl-pmc9",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:14:45.428231Z",
          "start_time": "2026-02-16T14:14:45.423285Z"
        }
      },
      "source": [
        "max_seq_len = 96\n",
        "\n",
        "max_midi_files=10240\n",
        "batch_size=32\n",
        "hidden_dim=256\n",
        "rnn_layers=5\n",
        "\n",
        "epochs=50\n",
        "early_stopping = 3\n",
        "\n",
        "learning_rate=0.001\n",
        "weight_decay=0.0001\n",
        "max_norm=1.0\n",
        "\n",
        "MODEL_FILENAME = '/content/drive/MyDrive/modele_ai/autoencoder.ckpt'"
      ],
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNZAypR3wF_6",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:16:28.438550Z",
          "start_time": "2026-02-16T14:16:28.433520Z"
        }
      },
      "source": [
        "# Paths\n",
        "image_root = \"ai_playing_music/src/all_data/generated/my_complex_images/my_midi_images\"\n",
        "midi_root = \"ai_playing_music/src/all_data/generated/generated_complex_midi_processed\"\n",
        "image_root_test = \"ai_playing_music/src/all_data/generated/my_complex_images_test/my_midi_images\"\n",
        "midi_root_test = \"ai_playing_music/src/all_data/generated/generated_complex_midi_processed_test\"\n",
        "\n",
        "selected_image_path = \"/ai_playing_music/src/all_data/generated/my_complex_images/my_midi_images/my_midi_files/song_1/song_1-1.png\"\n",
        "\n",
        "# image_root = \"src/all_data/generated/my_complex_images/my_midi_images\"\n",
        "# midi_root = \"src/all_data/generated/generated_complex_midi_processed\"\n",
        "# image_root_test = \"src/all_data/generated/my_complex_images_test/my_midi_images\"\n",
        "# midi_root_test = \"src/all_data/generated/generated_complex_midi_processed_test\"\n",
        "\n",
        "# selected_image_path = \"src/all_data/generated/my_complex_images/my_midi_images/my_midi_files/song_1/song_1-1.png\""
      ],
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f-ShNog0Gcib",
        "outputId": "78dd50b9-ade5-49f2-ebef-6a3265a19644",
        "ExecuteTime": {
          "end_time": "2026-02-16T14:17:48.733339700Z",
          "start_time": "2026-02-16T14:16:31.773327Z"
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((HEIGHT, WIDTH)),\n",
        "    transforms.RandomAffine(degrees=0, shear=2),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "\n",
        "dataset = MusicImageDataset(image_root, midi_root, image_transform, max_midi_files=24, modify_image=False)\n",
        "val_dataset = MusicImageDataset(image_root_test, midi_root_test, image_transform, max_midi_files=8, modify_image=False)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "cae = AE()\n",
        "epochs = epochs\n",
        "\n",
        "params_to_optimize = [\n",
        "    {'params': cae.parameters()}\n",
        "]\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optim = torch.optim.Adam(params_to_optimize, lr=learning_rate, weight_decay=1e-05)\n",
        "cae.to(device)\n",
        "\n",
        "best_val_loss = 1000000\n",
        "best_epoch = 0\n",
        "#Training loop\n",
        "t1 = datetime.datetime.now()\n",
        "print(\"Start training..\")\n",
        "for epoch in range(epochs):\n",
        "    print('> Epoch ' + str(epoch + 1))\n",
        "    train_loss = train_epoch(cae, device, dataloader, loss_fn, optim)\n",
        "    print(\"Evaluating on test set...\")\n",
        "    val_loss = test_epoch(cae,device, val_dataloader, loss_fn)\n",
        "    print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}.'.format(epoch + 1, epochs, train_loss, val_loss))\n",
        "    print('Plotting results...')\n",
        "    # plot_ae_outputs(cae, \"train_dataset\", epoch, dataset, device,n=5)\n",
        "    plot_ae_outputs(cae, \"test_dataset\", epoch, val_dataset, device,n=8)\n",
        "    if val_loss <= best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            checkpoint(cae, best_epoch, best_val_loss, MODEL_FILENAME)\n",
        "    elif epoch - best_epoch > early_stopping:\n",
        "        print(f\"Early stopped training at epoch {epoch}\")\n",
        "        model, _, _ = resume(cae, MODEL_FILENAME)\n",
        "        break  # terminate the training loop\n",
        "print(\"Total training time:\",datetime.datetime.now()-t1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Selected 24 images.\n",
            "Selected 8 images.\n",
            "Start training..\n",
            "> Epoch 1\n",
            "Evaluating on test set...\n",
            "\n",
            " EPOCH 1/50 \t train loss 0.6967184543609619 \t val loss 0.8428537249565125.\n",
            "Plotting results...\n",
            "targets:  [0 1 2 3 4 5 6 7]\n",
            "t_idx:  {0: np.int64(0), 1: np.int64(1), 2: np.int64(2), 3: np.int64(3), 4: np.int64(4), 5: np.int64(5), 6: np.int64(6), 7: np.int64(7)}\n",
            "2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected 4D input (got 3D input)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-555273850.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Plotting results...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# plot_ae_outputs(cae, \"train_dataset\", epoch, dataset, device,n=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mplot_ae_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbest_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2546411705.py\u001b[0m in \u001b[0;36mplot_ae_outputs\u001b[0;34m(cae, dataset_opt, epoch, dataset, device, n)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mcae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mrec_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2606944154.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3318259331.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3318259331.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# exponential_average_factor is set to self.momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"expected 4D input (got {input.dim()}D input)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected 4D input (got 3D input)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 6400x3200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 53
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}